

# Customer 360 Data Integration Project

## ğŸ“‹ Overview
This project implements a comprehensive Customer 360 Data Integration solution that extracts, transforms, and loads customer-related data from various sources into a centralized data warehouse (Amazon Redshift). The goal is to create a unified customer view for analytics and business intelligence dashboards.

![Customer 360 Data Integration Mindmap](https://cdn1.genspark.ai/user-upload-image/imagen_generated/80467853-7a20-42be-bea0-fa73e9b2efcd)

## ğŸ—ï¸ Architecture

The solution follows a modern data architecture with the following components:

- **Data Sources**: Multiple customer data touchpoints
- **Ingestion Layer**: Apache Airflow for orchestration
- **Staging Area**: Amazon S3 for raw data storage
- **Transformation Layer**: dbt for data modeling and transformation
- **Serving Layer**: Amazon Redshift as the data warehouse
- **BI Layer**: Power BI/Tableau for visualization and analytics

![Project Architecture](Customer360DataIntegrationArchitecture.png)


## ğŸ”„ Data Pipeline

### Data Sources
- **CRM Data** (MySQL)
  - Generated with Faker library
  - Contains customer profile information
- **Salesforce Data**
  - Extracted via simple-salesforce Python package
  - Captures sales interactions and opportunities
- **Marketing Data** (Google Analytics)
  - BigQuery public datasets: `bigquery-public-data.google_analytics_sample.ga_sessions_*`
  - Provides digital customer journey data
- **Offline Transactions** (CSV Files)
  - Generated with Mockaroo
  - Contains in-store/offline purchase information

### ETL Process
1. **Extract**: Airflow DAGs pull data from each source
2. **Load**: Raw data stored in S3 buckets
3. **Transform**: dbt models clean, standardize, and join data
4. **Validate**: great_expectations library ensures data quality
5. **Load**: Final models deployed to Amazon Redshift REPORTING schema

## ğŸ› ï¸ Technologies

- **Orchestration**: Apache Airflow
- **Storage**: Amazon S3, Amazon Redshift
- **Transformation**: dbt (data build tool)
- **Data Validation**: great_expectations
- **Visualization**: Power BI/Tableau
- **Infrastructure**: Docker, GitHub Actions

## ğŸ“¦ Project Structure

```
customer_360_project/
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ customer_360_extract.py
â”‚       â”œâ”€â”€ load_to_redshift_staging.py
â”‚       â””â”€â”€ dbt_transform.py           # The DAG we're focusing on
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/                   # Stage 1: Cleaned source data
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_crm_customers.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_salesforce_contacts.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_ga_sessions.sql
â”‚   â”‚   â”‚   â””â”€â”€ stg_transactions.sql
â”‚   â”‚   â””â”€â”€ marts/                     # Stage 2: Business-specific models
â”‚   â”‚       â”œâ”€â”€ customer_360_profile.sql
â”‚   â”‚       â”œâ”€â”€ customer_engagement.sql
â”‚   â”‚       â””â”€â”€ channel_attribution.sql
â”‚   â”œâ”€â”€ dbt_project.yml               # dbt project configuration
â”‚   â”œâ”€â”€ profiles.yml                  # Database connection profiles
â”‚   â””â”€â”€ packages.yml                  # dbt package dependencies
â””â”€â”€ docker-compose.yml                # For containerization

```

## âš™ï¸ Setup and Installation

### Prerequisites
- Docker and Docker Compose
- AWS Account with S3 and Redshift access
- Salesforce Developer Account
- Python 3.8+

### Getting Started

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/customer_360.git
cd customer_360
```

2. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your credentials
```

3. **Start the local environment**
```bash
docker-compose up -d
```

4. **Initialize Airflow connections**
```bash
docker-compose exec airflow airflow connections add 'aws_default' \
    --conn-type 'aws' \
    --conn-login '<your-access-key>' \
    --conn-password '<your-secret-key>' \
    --conn-extra '{"region_name": "us-east-1"}'
```

5. **Initialize dbt**
```bash
cd models
dbt deps
dbt seed
```

## ğŸ“Š Data Models

### Core Models

#### Customer 360 Unified Profile
- Combines data from all sources into a single customer view
- Includes demographic, behavioral, and transactional data
- Provides a 360-degree view of the customer journey

#### Customer Engagement Metrics
- Tracks customer interactions across channels
- Calculates engagement scores and activity levels
- Identifies preferred communication channels

#### Channel Attribution
- Attributes conversions to marketing channels
- Provides insight into the customer acquisition journey
- Helps optimize marketing spend


![Customer360OverviewDashboard](Customer360OverviewDashboard.png)


![CustomerJourney](CustomerJourney.png)


## ğŸ” Monitoring & CI/CD

- **GitHub Actions**: Automated testing and deployment
- **Docker**: Containerized environment for consistent execution
- **dbt tests**: Data quality and integrity validation
- **Airflow monitoring**: DAG execution tracking and alerts

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Contact

If you have any questions or want to contribute, please reach out!

---

*This README is part of the Customer 360 Data Integration Project*
